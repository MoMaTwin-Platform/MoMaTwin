from typing import Dict, Callable, List
import collections
import torch
import torch.nn as nn

from torch.utils.data import Subset
import torch.distributed as dist
import random
import numpy as np
from typing import Union
from scipy.spatial.transform import Rotation

def dict_apply(
        x: Dict[str, torch.Tensor], 
        func: Callable[[torch.Tensor], torch.Tensor],
        ignore_keys: List[str] = []
        ) -> Dict[str, torch.Tensor]:
    result = dict()
    for key, value in x.items():
        if key not in ignore_keys:
            if isinstance(value, dict):
                result[key] = dict_apply(value, func)
            else:
                result[key] = func(value)
    return result

def decode_text(encoded_array:Union[torch.Tensor, np.ndarray]) -> str:
    '''
    Decode text from encoded array
    '''
    if isinstance(encoded_array, str):
        return encoded_array
    if len(encoded_array) == 0:
        return ''
    
    if isinstance(encoded_array, torch.Tensor):
        encoded_array = encoded_array.cpu().numpy()
    
    # è¿‡æ»¤æ‰ 0 å¹¶è½¬æ¢ä¸ºå­—ç¬¦
    filtered_text = encoded_array[encoded_array != 0]

    return ''.join(map(chr, filtered_text))

def split_dataset_with_list(dataset, train_ratio=0.8):
    indices = torch.randperm(len(dataset)).tolist()
    train_size = int(len(dataset) * train_ratio)
    
    train_indices = indices[:train_size]
    test_indices = indices[train_size:]
    
    train_dataset = Subset(dataset, train_indices)
    test_dataset = Subset(dataset, test_indices)
    
    return train_dataset, test_dataset, train_indices, test_indices

def shuffle_sub_dataset(subset, seed):
    random.seed(seed)
    random.shuffle(subset.indices)
    
def print_rank0(*args, **kwargs):
    """
    Print the provided arguments only if this is rank 0.
    """
    if dist.is_initialized():
        if dist.get_rank() == 0:
            print(*args, **kwargs)
    else:
        print(*args, **kwargs)


def actions_to_relative(actions, add_noise=False, noise_scale=[0.05,0.05,0.05,0.05,0.05,0.05]):
    """Convert absolute actions to relative actions
    
    Args:
        actions: numpy array of shape [horizon, action_dim]
                action_dim=14, [left_arm(7), right_arm(7)]
                Each arm: [x,y,z,roll,pitch,yaw,gripper]
        add_noise: bool, whether to add noise to the first frame
        noise_scale: list of 6 numbers, scale of noise for [x,y,z,roll,pitch,yaw]
    
    Returns:
        relative_actions: numpy array of shape [horizon, action_dim]
    """
    horizon, _ = actions.shape
    relative_actions = np.zeros_like(actions)
    
    # å¤„ç†å·¦è‡‚å’Œå³è‡‚
    for arm_idx in range(2):
        start_idx = arm_idx * 7
        
        # è·å–ç¬¬ä¸€å¸§çš„å˜æ¢çŸ©é˜µ
        ref_pos = actions[0, start_idx:start_idx+3]
        ref_rot = Rotation.from_euler('xyz', actions[0, start_idx+3:start_idx+6])
        ref_matrix = np.eye(4)
        ref_matrix[:3, :3] = ref_rot.as_matrix()
        ref_matrix[:3, 3] = ref_pos
        
        # å¦‚æœéœ€è¦åŠ å™ªå£°ï¼Œç»™ç¬¬ä¸€å¸§åŠ å™ªå£°
        if add_noise:
            noise = np.random.normal(scale=noise_scale, size=6)
            noisy_pos = ref_pos + noise[:3]
            noisy_rot = Rotation.from_euler('xyz', actions[0, start_idx+3:start_idx+6] + noise[3:])
            noisy_matrix = np.eye(4)
            noisy_matrix[:3, :3] = noisy_rot.as_matrix()
            noisy_matrix[:3, 3] = noisy_pos
            ref_matrix_inv = np.linalg.inv(noisy_matrix)
        else:
            ref_matrix_inv = np.linalg.inv(ref_matrix)
        
        # è®¡ç®—æ‰€æœ‰å¸§çš„ç›¸å¯¹å˜æ¢ï¼ˆåŒ…æ‹¬ç¬¬ä¸€å¸§ï¼‰
        for i in range(horizon):
            # å½“å‰å¸§çš„å˜æ¢çŸ©é˜µ
            curr_pos = actions[i, start_idx:start_idx+3]
            curr_rot = Rotation.from_euler('xyz', actions[i, start_idx+3:start_idx+6])
            curr_matrix = np.eye(4)
            curr_matrix[:3, :3] = curr_rot.as_matrix()
            curr_matrix[:3, 3] = curr_pos
            
            # è®¡ç®—ç›¸å¯¹å˜æ¢
            relative_matrix = ref_matrix_inv @ curr_matrix
            
            # æå–ç›¸å¯¹ä½ç½®å’Œæ—‹è½¬
            relative_actions[i, start_idx:start_idx+3] = relative_matrix[:3, 3]
            relative_actions[i, start_idx+3:start_idx+6] = Rotation.from_matrix(
                relative_matrix[:3, :3]).as_euler('xyz')
            
            # Gripperä¿æŒä¸å˜
            relative_actions[i, start_idx+6] = actions[i, start_idx+6]
    
    return relative_actions

def relative_to_actions(relative_actions, start_pose):
    """Convert relative actions back to absolute actions
    
    Args:
        relative_actions: numpy array of shape [horizon-1, action_dim]
                         ä»ç¬¬äºŒå¸§å¼€å§‹çš„ç›¸å¯¹ä½å§¿åºåˆ—
                         action_dim=14, [left_arm(7), right_arm(7)]
                         Each arm: [x,y,z,roll,pitch,yaw,gripper]
        start_pose: numpy array of shape [action_dim]
                   ç¬¬ä¸€å¸§çš„ç»å¯¹ä½å§¿
    
    Returns:
        actions: numpy array of shape [horizon, action_dim]
                åŒ…å«start_poseå’Œè½¬æ¢åçš„ç»å¯¹ä½å§¿åºåˆ—
    """
    horizon = relative_actions.shape[0] + 1  # åŠ 1æ˜¯å› ä¸ºrelative_actionsä¸åŒ…å«ç¬¬ä¸€å¸§
    actions = np.zeros((horizon, relative_actions.shape[1]))
    
    # è®¾ç½®ç¬¬ä¸€å¸§ä¸ºç»™å®šçš„start_pose
    actions[0] = start_pose
    
    # å¤„ç†å·¦è‡‚å’Œå³è‡‚
    for arm_idx in range(2):
        start_idx = arm_idx * 7
        
        # ä½¿ç”¨start_poseåˆ›å»ºå‚è€ƒå˜æ¢çŸ©é˜µ
        ref_pos = start_pose[start_idx:start_idx+3]
        ref_rot = Rotation.from_euler('xyz', start_pose[start_idx+3:start_idx+6])
        ref_matrix = np.eye(4)
        ref_matrix[:3, :3] = ref_rot.as_matrix()
        ref_matrix[:3, 3] = ref_pos
        
        # ä»ç¬¬äºŒå¸§å¼€å§‹è®¡ç®—ç»å¯¹ä½å§¿
        for i in range(horizon-1):  # horizon-1æ˜¯relative_actionsçš„é•¿åº¦
            # å½“å‰ç›¸å¯¹ä½å§¿çš„å˜æ¢çŸ©é˜µ
            relative_pos = relative_actions[i, start_idx:start_idx+3]
            relative_rot = Rotation.from_euler('xyz', relative_actions[i, start_idx+3:start_idx+6])
            relative_matrix = np.eye(4)
            relative_matrix[:3, :3] = relative_rot.as_matrix()
            relative_matrix[:3, 3] = relative_pos
            
            # è®¡ç®—ç»å¯¹å˜æ¢
            abs_matrix = ref_matrix @ relative_matrix
            
            # æå–ç»å¯¹ä½ç½®å’Œæ—‹è½¬ï¼Œå­˜å‚¨åœ¨ç¬¬i+1å¸§
            actions[i+1, start_idx:start_idx+3] = abs_matrix[:3, 3]
            actions[i+1, start_idx+3:start_idx+6] = Rotation.from_matrix(
                abs_matrix[:3, :3]).as_euler('xyz')
            
            # Gripperä¿æŒä¸å˜
            actions[i+1, start_idx+6] = relative_actions[i, start_idx+6]
    
    return actions[1:] # ä¸åŒ…å«start_pose

import numpy as np
from scipy import stats
from scipy.signal import savgol_filter
from scipy.ndimage import gaussian_filter1d


def remove_outliers(data, threshold=3):
    """
    ä½¿ç”¨Z-scoreæ–¹æ³•ç§»é™¤å¼‚å¸¸å€¼ã€‚
    
    å‚æ•°:
        data: è¾“å…¥æ•°æ®æ•°ç»„
        threshold: Z-scoreé˜ˆå€¼ï¼Œé»˜è®¤ä¸º3
        
    è¿”å›:
        è¿‡æ»¤åçš„æ•°æ®
    """
    # # å¦‚æœæ•°æ®ç‚¹å¤ªå°‘æˆ–å…¨ä¸ºç›¸åŒå€¼ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
    # if len(data) < 3 or np.all(data == data[0]):
    #     return data.copy()

    # # è®¡ç®—æ ‡å‡†å·®ï¼Œé¿å…ç¾éš¾æ€§æŠµæ¶ˆ
    # std = np.std(data)
    # if std < 1e-10:  # å¦‚æœæ ‡å‡†å·®æ¥è¿‘0ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
    #     return data.copy()
        
    # # è®¡ç®—Z-score
    # try:
    #     z_scores = np.abs(stats.zscore(data))
    # except:
    #     # å¦‚æœæ— æ³•è®¡ç®—Z-scoreï¼ˆä¾‹å¦‚æ‰€æœ‰å€¼ç›¸åŒï¼‰ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
    #     return data.copy()
        
    filtered_data = data.copy()
    
    # # æ‰¾å‡ºå¼‚å¸¸å€¼
    # mask = z_scores > threshold
    
    # # å¦‚æœå¼‚å¸¸å€¼å¤ªå¤šï¼Œå¯èƒ½æ˜¯æ•°æ®æœ¬èº«å°±æœ‰è¾ƒå¤§æ³¢åŠ¨ï¼Œä¿æŒåŸæ ·
    # if np.sum(mask) > len(data) * 0.4:  # å¦‚æœè¶…è¿‡40%çš„æ•°æ®è¢«æ ‡è®°ä¸ºå¼‚å¸¸
    #     return data.copy()
        
    # # æ ‡è®°å¼‚å¸¸å€¼ä¸ºNaN
    # filtered_data[mask] = np.nan
    
    # # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½å˜æˆäº†NaN
    # if np.all(np.isnan(filtered_data)):
    #     return data.copy()
        
    # # ç”¨æ’å€¼å¡«å……NaNå€¼
    # nan_mask = np.isnan(filtered_data)
    
    # # ç¡®ä¿æœ‰éNaNå€¼å¯ä»¥ç”¨äºæ’å€¼
    # if np.any(~nan_mask):
    #     filtered_data[nan_mask] = np.interp(
    #         np.flatnonzero(nan_mask), 
    #         np.flatnonzero(~nan_mask), 
    #         filtered_data[~nan_mask]
    #     )
    
    return filtered_data

def remove_jumps(data, threshold=1.0):
    """
    æ£€æµ‹å¹¶ä¿®æ­£æ•°æ®ä¸­çš„çªç„¶è·³å˜ã€‚
    
    å‚æ•°:
        data: è¾“å…¥æ•°æ®æ•°ç»„
        threshold: è·³å˜æ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤ä¸º1.0
        
    è¿”å›:
        ä¿®æ­£åçš„æ•°æ®
    """
    # å¦‚æœæ•°æ®ç‚¹å¤ªå°‘ï¼Œæ— æ³•æœ‰æ•ˆæ£€æµ‹è·³å˜ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
    if len(data) < 3:
        return data.copy()
        
    result = data.copy()
    
    # è®¡ç®—ç›¸é‚»ç‚¹ä¹‹é—´çš„å·®å€¼
    try:
        diffs = np.abs(np.diff(result))
    except:
        # å¦‚æœæ— æ³•è®¡ç®—å·®å€¼ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
        return data.copy()
        
    # æ‰¾å‡ºå¤§äºé˜ˆå€¼çš„è·³å˜ç‚¹
    jump_indices = np.where(diffs > threshold)[0]
    
    # å¦‚æœè·³å˜ç‚¹å¤ªå¤šï¼Œè¯´æ˜æ•°æ®æœ¬èº«æ³¢åŠ¨è¾ƒå¤§ï¼Œä¿æŒåŸæ ·
    if len(jump_indices) > len(data) * 0.3:  # å¦‚æœè¶…è¿‡30%çš„ç‚¹è¢«æ ‡è®°ä¸ºè·³å˜
        return data.copy()
    
    # å¤„ç†æ¯ä¸ªè·³å˜ç‚¹
    for idx in jump_indices:
        # ç”¨å‰åç‚¹çš„å¹³å‡å€¼æ›¿æ¢è·³å˜
        if idx > 0 and idx < len(result) - 1:
            # å–è·³å˜å‰åçš„å¹³å‡å€¼
            result[idx+1] = (result[idx] + result[idx+2]) / 2
        elif idx == len(result) - 2:  # å¦‚æœæ˜¯å€’æ•°ç¬¬äºŒä¸ªç‚¹
            result[idx+1] = result[idx]  # ç”¨å‰ä¸€ä¸ªç‚¹çš„å€¼æ›¿æ¢
    
    return result

def smooth_data(data, window_length=None, polyorder=3, iterations=1, strong_smooth=False):
    """
    ä½¿ç”¨Savitzky-Golayæ»¤æ³¢å™¨å¹³æ»‘æ•°æ®ã€‚
    
    å‚æ•°:
        data: è¾“å…¥æ•°æ®æ•°ç»„
        window_length: çª—å£é•¿åº¦ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™è‡ªåŠ¨è®¡ç®—
        polyorder: å¤šé¡¹å¼é˜¶æ•°ï¼Œé»˜è®¤ä¸º3
        iterations: å¹³æ»‘è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º1
        strong_smooth: æ˜¯å¦ä½¿ç”¨å¼ºå¹³æ»‘æ¨¡å¼ï¼Œé»˜è®¤ä¸ºFalse
        
    è¿”å›:
        å¹³æ»‘åçš„æ•°æ®
    """
    # ç¡®ä¿æ•°æ®è‡³å°‘æœ‰3ä¸ªç‚¹
    if len(data) < 3:
        return data.copy()
        
    # è®¡ç®—åˆé€‚çš„çª—å£é•¿åº¦
    if window_length is None:
        if strong_smooth:
            # å¼ºå¹³æ»‘æ¨¡å¼ä¸‹ä½¿ç”¨æ›´å¤§çš„çª—å£
            window_length = min(51, len(data) - 1)
        else:
            window_length = min(21, len(data) - 1)
        
    # ç¡®ä¿çª—å£é•¿åº¦ä¸ºå¥‡æ•°ä¸”å°äºç­‰äºæ•°æ®é•¿åº¦
    window_length = min(window_length, len(data) - 1)
    if window_length % 2 == 0:  # ç¡®ä¿çª—å£é•¿åº¦ä¸ºå¥‡æ•°
        window_length -= 1
    
    # ç¡®ä¿çª—å£é•¿åº¦è‡³å°‘ä¸º3
    window_length = max(3, window_length)
    
    # å¦‚æœæ•°æ®é•¿åº¦å°äºçª—å£é•¿åº¦ï¼Œä½¿ç”¨é«˜æ–¯æ»¤æ³¢
    if window_length >= len(data):
        sigma = 3.0 if strong_smooth else 1.0
        return gaussian_filter1d(data, sigma=sigma)
    
    # åœ¨å¼ºå¹³æ»‘æ¨¡å¼ä¸‹ä½¿ç”¨æ›´ä½çš„å¤šé¡¹å¼é˜¶æ•°
    if strong_smooth:
        polyorder = min(2, polyorder)
    
    # ç¡®ä¿å¤šé¡¹å¼é˜¶æ•°å°äºçª—å£é•¿åº¦
    polyorder = min(polyorder, window_length - 1)
    
    smooth_data_result = data.copy()
    
    try:
        # åº”ç”¨å¤šæ¬¡å¹³æ»‘
        for _ in range(iterations):
            smooth_data_result = savgol_filter(smooth_data_result, window_length, polyorder)
            
        # å¦‚æœéœ€è¦å¼ºå¹³æ»‘ï¼Œå†åº”ç”¨é«˜æ–¯æ»¤æ³¢
        if strong_smooth:
            smooth_data_result = gaussian_filter1d(smooth_data_result, sigma=2.0)
            
        return smooth_data_result
        
    except Exception as e:
        # å¦‚æœsavgol_filterå¤±è´¥ï¼Œä½¿ç”¨é«˜æ–¯æ»¤æ³¢ä½œä¸ºå¤‡é€‰
        print(f"Savgol filter failed: {e}, using Gaussian filter instead")
        sigma = 3.0 if strong_smooth else 1.0
        return gaussian_filter1d(data, sigma=sigma)
    
def process_car_pose_to_base_velocity(car_pose, 
                                    outlier_threshold=3, 
                                    jump_threshold=1.0, 
                                    smooth_iterations=3, 
                                    strong_smooth=True):
    """
    ğŸ¯ å¤„ç†car_poseæ•°æ®ï¼Œè½¬æ¢ä¸ºæœ¬ä½“åæ ‡ç³»base_velocity_decomposedï¼Œä¸batch_process_json_data.pyå®Œå…¨ä¸€è‡´ã€‚
    åŒ…å«å®Œæ•´çš„å¼‚å¸¸å€¼å¤„ç†ã€è§’åº¦unwrapã€è¿‡æ»¤å’Œå¹³æ»‘å¤„ç†ï¼Œä»¥åŠæœ¬ä½“åæ ‡ç³»é€Ÿåº¦è®¡ç®—ã€‚
    
    å‚æ•°:
        car_pose: è¾“å…¥çš„car_poseæ•°æ®ï¼Œshape: (n, 3) [x, y, angle]
        outlier_threshold: å¼‚å¸¸å€¼æ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤ä¸º3
        jump_threshold: è·³å˜æ£€æµ‹é˜ˆå€¼ï¼Œé»˜è®¤ä¸º1.0
        smooth_iterations: å¹³æ»‘è¿­ä»£æ¬¡æ•°ï¼Œé»˜è®¤ä¸º3
        strong_smooth: æ˜¯å¦ä½¿ç”¨å¼ºå¹³æ»‘æ¨¡å¼ï¼Œé»˜è®¤ä¸ºTrue
        
    è¿”å›:
        dict: åŒ…å«å¤„ç†åçš„æ•°æ®
            - 'base_velocity_decomposed': shape (n, 3) [vx_body, vy_body, vyaw] (æœ¬ä½“åæ ‡ç³»)
            - 'valid': bool, æ˜¯å¦æœ‰æ•ˆï¼ˆé€šè¿‡é€Ÿåº¦èŒƒå›´æ£€æŸ¥ï¼‰
    """
    # å®šä¹‰é€Ÿåº¦é™åˆ¶ï¼ˆä¸data_analysis_filter.pyä¸­å®Œå…¨ä¸€è‡´ï¼‰
    velocity_limits = {
        'vx': {'min': -0.5, 'max': 0.5},
        'vy': {'min': -0.5, 'max': 0.5}, 
        'vyaw': {'min': -1.6, 'max': 1.6}
    }
    
    # å¤„ç†ç©ºæ•°æ®æˆ–å•ç‚¹æ•°æ®
    if len(car_pose) == 0:
        return {
            'base_velocity_decomposed': np.zeros((0, 3)),
            'valid': False
        }

    if len(car_pose) == 1:
        return {
            'base_velocity_decomposed': np.zeros((1, 3)),
            'valid': True  # å•ç‚¹æ•°æ®è®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
        }

    # ğŸ¯ æ­¥éª¤1: æå–ä½ç½®å’Œè§’åº¦æ•°æ®ï¼Œå¹¶è¿›è¡Œè§’åº¦å±•å¼€
    x_values = car_pose[:, 0].copy()
    y_values = car_pose[:, 1].copy()
    angle_values = car_pose[:, 2].copy()

    # ğŸ¯ è§’åº¦å±•å¼€å¤„ç†ï¼Œé¿å…è·³å˜ï¼ˆç§»åˆ°å‡½æ•°å†…éƒ¨ï¼‰
    angle_values_unwrapped = np.unwrap(angle_values)

    # ğŸ¯ æ­¥éª¤2-4: å¼‚å¸¸å€¼å¤„ç†ã€è·³å˜ä¿®æ­£ã€å¹³æ»‘å¤„ç†
    # å¼‚å¸¸å€¼å¤„ç†
    x_filtered = remove_outliers(x_values, outlier_threshold)
    y_filtered = remove_outliers(y_values, outlier_threshold)
    angle_filtered = remove_outliers(angle_values_unwrapped, outlier_threshold)

    # è·³å˜ä¿®æ­£
    x_filtered = remove_jumps(x_filtered, jump_threshold)
    y_filtered = remove_jumps(y_filtered, jump_threshold)
    angle_filtered = remove_jumps(angle_filtered, jump_threshold)

    # å¹³æ»‘å¤„ç†
    window_length = min(51 if strong_smooth else 21, len(x_filtered) - 1)
    if window_length % 2 == 0:
        window_length -= 1
    window_length = max(3, window_length)

    x_smooth = smooth_data(x_filtered, window_length, polyorder=2 if strong_smooth else 3, 
                          iterations=smooth_iterations, strong_smooth=strong_smooth)
    y_smooth = smooth_data(y_filtered, window_length, polyorder=2 if strong_smooth else 3, 
                          iterations=smooth_iterations, strong_smooth=strong_smooth)
    angle_smooth = smooth_data(angle_filtered, window_length, polyorder=2 if strong_smooth else 3, 
                              iterations=smooth_iterations, strong_smooth=strong_smooth)

    # ğŸ¯ æ­¥éª¤5: ä½¿ç”¨ä¸data_processor.pyå®Œå…¨ä¸€è‡´çš„æœ¬ä½“åæ ‡ç³»é€Ÿåº¦è®¡ç®—æ–¹æ³•
    dt = 1/20  # 20Hzé‡‡æ ·é¢‘ç‡
    
    # è®¡ç®—å…¨å±€ä½ç§»
    x_diff = np.diff(x_smooth)
    y_diff = np.diff(y_smooth)
    angle_diff = np.diff(angle_smooth)
    
    # è·å–å½“å‰å¸§çš„è§’åº¦ï¼ˆç”¨äºåæ ‡å˜æ¢ï¼‰
    current_theta = angle_smooth[:-1]  # shape: (n-1,)
    
    # ğŸ¯ åæ ‡å˜æ¢ï¼šä»å…¨å±€åæ ‡ç³»åˆ°æœ¬ä½“åæ ‡ç³»ï¼ˆä¸data_processor.pyä¸€è‡´ï¼‰
    cos_theta = np.cos(current_theta)
    sin_theta = np.sin(current_theta)
    
    # ğŸ¯ è®¡ç®—æœ¬ä½“åæ ‡ç³»ä¸‹çš„é€Ÿåº¦
    vx_body = (x_diff * cos_theta + y_diff * sin_theta) / dt   # å‰è¿›é€Ÿåº¦ï¼ˆæœ¬ä½“åæ ‡ç³»ï¼‰
    vy_body = (-x_diff * sin_theta + y_diff * cos_theta) / dt  # å·¦ä¾§é€Ÿåº¦ï¼ˆæœ¬ä½“åæ ‡ç³»ï¼‰
    vyaw = angle_diff / dt  # è§’é€Ÿåº¦
    
    # åœ¨å¼€å¤´æ·»åŠ é›¶é€Ÿåº¦ä»¥åŒ¹é…åŸå§‹æ•°æ®é•¿åº¦
    vx_array = np.concatenate([[0], vx_body])
    vy_array = np.concatenate([[0], vy_body])
    vyaw_array = np.concatenate([[0], vyaw])
    
    base_velocity_decomposed = np.stack([vx_array, vy_array, vyaw_array], axis=1)
    
    # ğŸ¯ æ­¥éª¤6: é€Ÿåº¦èŒƒå›´æ£€æŸ¥ï¼ˆä¸data_analysis_filter.pyä¸€è‡´ï¼‰
    valid = True
    
    # # æ£€æŸ¥æ¯ä¸ªé€Ÿåº¦åˆ†é‡æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
    # for vx_val in vx_body:
    #     if vx_val < velocity_limits['vx']['min'] or vx_val > velocity_limits['vx']['max']:
    #         valid = False
    #         break
    
    # if valid:  # åªæœ‰vxé€šè¿‡æ£€æŸ¥æ‰ç»§ç»­æ£€æŸ¥vy
    #     for vy_val in vy_body:
    #         if vy_val < velocity_limits['vy']['min'] or vy_val > velocity_limits['vy']['max']:
    #             valid = False
    #             break
    
    # if valid:  # åªæœ‰vxå’Œvyéƒ½é€šè¿‡æ£€æŸ¥æ‰ç»§ç»­æ£€æŸ¥vyaw
    #     for vyaw_val in vyaw:
    #         if vyaw_val < velocity_limits['vyaw']['min'] or vyaw_val > velocity_limits['vyaw']['max']:
    #             valid = False
    #             break

    return {
        'base_velocity_decomposed': base_velocity_decomposed,
        'valid': valid
    }
    