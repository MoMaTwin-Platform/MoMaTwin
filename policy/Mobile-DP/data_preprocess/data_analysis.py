#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†æå·¥å…· - data_analysis.py

åŠŸèƒ½ï¼š
1. éå†å¤„ç†å¥½çš„æ•°æ®é›†ç›®å½•
2. å…¨å±€ç»Ÿè®¡ car_pose å’Œ velocity_decomposed çš„æœ€å¤§å€¼/æœ€å°å€¼/å¹³å‡å€¼/æ ‡å‡†å·®
3. ç»˜åˆ¶ velocity_decomposed å„ä¸ªåˆ†é‡ï¼ˆvx, vy, vyawï¼‰çš„é€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾
4. ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š

ä½œè€…: @yinyuehao
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from tqdm import tqdm
import argparse
import glob
from collections import defaultdict
import pandas as pd

# è®¾ç½®éäº¤äº’æ¨¡å¼
matplotlib.use('Agg')

class DatasetAnalyzer:
    """
    æ•°æ®é›†åˆ†æå™¨ - ç”¨äºåˆ†æå¤„ç†åçš„è½¨è¿¹æ•°æ®
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.car_pose_data = {
            'x': [],
            'y': [],
            'angle': []
        }
        self.velocity_data = {
            'vx': [],
            'vy': [],
            'vyaw': []
        }
        self.trajectory_stats = []
        self.total_trajectories = 0
        self.total_frames = 0
        
        # ğŸ¯ æ–°å¢ï¼šå¼‚å¸¸é«˜é€Ÿè½¨è¿¹è·Ÿè¸ª
        self.abnormal_speed_trajectories = []  # åŒ…å«å¼‚å¸¸é«˜é€Ÿçš„è½¨è¿¹ä¿¡æ¯
        
    def find_processed_json_files(self, processed_data_dir):
        """
        é€’å½’æŸ¥æ‰¾æ‰€æœ‰å¤„ç†è¿‡çš„JSONæ–‡ä»¶
        
        Args:
            processed_data_dir: å¤„ç†æ•°æ®çš„æ ¹ç›®å½•
            
        Returns:
            JSONæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        json_files = []
        
        # éå†ç›®å½•ç»“æ„ï¼šprocessed_data/{robot_id}/{task_name}/{trajectory_name}/{trajectory_name}.json
        if not os.path.exists(processed_data_dir):
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {processed_data_dir}")
            return json_files
        
        # æŸ¥æ‰¾æ¨¡å¼ï¼š*/*/*.json (è·³è¿‡trajectory.pngç­‰æ–‡ä»¶)
        search_pattern = os.path.join(processed_data_dir, "*", "*", "*", "*.json")
        potential_files = glob.glob(search_pattern)
        
        for file_path in potential_files:
            # ç¡®ä¿æ˜¯è½¨è¿¹JSONæ–‡ä»¶ï¼ˆä¸æ˜¯å…¶ä»–é…ç½®æ–‡ä»¶ï¼‰
            if file_path.endswith('.json'):
                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸çˆ¶ç›®å½•åç§°åŒ¹é…ï¼ˆè½¨è¿¹æ–‡ä»¶ç‰¹å¾ï¼‰
                file_name = os.path.basename(file_path)
                parent_dir = os.path.basename(os.path.dirname(file_path))
                
                if file_name.replace('.json', '') == parent_dir:
                    json_files.append(file_path)
        
        print(f"ğŸ” æ‰¾åˆ° {len(json_files)} ä¸ªå¤„ç†è¿‡çš„JSONæ–‡ä»¶")
        return sorted(json_files)
    
    def load_and_analyze_json(self, json_path):
        """
        åŠ è½½å¹¶åˆ†æå•ä¸ªJSONæ–‡ä»¶
        
        Args:
            json_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸æˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            frames = data.get('data', [])
            if not frames:
                print(f"âš ï¸  ç©ºæ•°æ®æ–‡ä»¶: {json_path}")
                return None
            
            # æå–car_poseå’Œvelocity_decomposedæ•°æ®
            trajectory_car_pose = {
                'x': [],
                'y': [],
                'angle': []
            }
            trajectory_velocity = {
                'vx': [],
                'vy': [],
                'vyaw': []
            }
            
            for frame in frames:
                # æå–car_poseæ•°æ®
                car_pose = frame.get('car_pose', [0, 0, 0])
                if len(car_pose) >= 3:
                    trajectory_car_pose['x'].append(car_pose[0])
                    trajectory_car_pose['y'].append(car_pose[1])
                    trajectory_car_pose['angle'].append(car_pose[2])
                
                # æå–velocity_decomposedæ•°æ®
                velocity_decomposed = frame.get('velocity_decomposed', [0, 0, 0])
                if len(velocity_decomposed) >= 3:
                    trajectory_velocity['vx'].append(velocity_decomposed[0])
                    trajectory_velocity['vy'].append(velocity_decomposed[1])
                    trajectory_velocity['vyaw'].append(velocity_decomposed[2])
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            for key in trajectory_car_pose:
                trajectory_car_pose[key] = np.array(trajectory_car_pose[key])
            for key in trajectory_velocity:
                trajectory_velocity[key] = np.array(trajectory_velocity[key])
            
            # ğŸ¯ æ–°å¢ï¼šæ£€æµ‹å¼‚å¸¸é«˜é€Ÿ
            abnormal_speed_info = self.detect_abnormal_speed(trajectory_velocity, json_path)
            
            # è®¡ç®—è½¨è¿¹ç»Ÿè®¡ä¿¡æ¯
            trajectory_stat = {
                'file_path': json_path,
                'trajectory_name': os.path.basename(json_path).replace('.json', ''),
                'num_frames': len(frames),
                'car_pose_stats': {},
                'velocity_stats': {},
                'abnormal_speed_info': abnormal_speed_info  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿä¿¡æ¯
            }
            
            # Car poseç»Ÿè®¡
            for key, values in trajectory_car_pose.items():
                if len(values) > 0:
                    trajectory_stat['car_pose_stats'][key] = {
                        'min': float(np.min(values)),
                        'max': float(np.max(values)),
                        'mean': float(np.mean(values)),
                        'std': float(np.std(values)),
                        'range': float(np.max(values) - np.min(values))
                    }
            
            # Velocityç»Ÿè®¡
            for key, values in trajectory_velocity.items():
                if len(values) > 0:
                    trajectory_stat['velocity_stats'][key] = {
                        'min': float(np.min(values)),
                        'max': float(np.max(values)),
                        'mean': float(np.mean(values)),
                        'std': float(np.std(values)),
                        'range': float(np.max(values) - np.min(values))
                    }
            
            return {
                'trajectory_stat': trajectory_stat,
                'car_pose_data': trajectory_car_pose,
                'velocity_data': trajectory_velocity
            }
            
        except Exception as e:
            print(f"âŒ åŠ è½½JSONæ–‡ä»¶å¤±è´¥: {json_path}, é”™è¯¯: {e}")
            return None
    
    def detect_abnormal_speed(self, trajectory_velocity, json_path):
        """
        æ£€æµ‹è½¨è¿¹ä¸­çš„å¼‚å¸¸é«˜é€Ÿæƒ…å†µ
        
        Args:
            trajectory_velocity: è½¨è¿¹é€Ÿåº¦æ•°æ®
            json_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            å¼‚å¸¸é«˜é€Ÿä¿¡æ¯å­—å…¸
        """
        # å¼‚å¸¸é«˜é€Ÿé˜ˆå€¼
        LINEAR_SPEED_THRESHOLD = 0.5  # m/s
        ANGULAR_SPEED_THRESHOLD = 0.6  # rad/s
        
        abnormal_info = {
            'has_abnormal_speed': False,
            'abnormal_types': [],
            'max_speeds': {},
            'abnormal_frame_counts': {},
            'abnormal_frame_percentages': {}
        }
        
        vx_data = trajectory_velocity.get('vx', np.array([]))
        vy_data = trajectory_velocity.get('vy', np.array([]))
        vyaw_data = trajectory_velocity.get('vyaw', np.array([]))
        
        total_frames = len(vx_data)
        
        # æ£€æµ‹vxå¼‚å¸¸é«˜é€Ÿ
        if len(vx_data) > 0:
            vx_abnormal = np.abs(vx_data) > LINEAR_SPEED_THRESHOLD
            abnormal_info['max_speeds']['vx'] = float(np.max(np.abs(vx_data)))
            abnormal_info['abnormal_frame_counts']['vx'] = int(np.sum(vx_abnormal))
            abnormal_info['abnormal_frame_percentages']['vx'] = float(np.sum(vx_abnormal) / total_frames * 100)
            
            if np.any(vx_abnormal):
                abnormal_info['has_abnormal_speed'] = True
                abnormal_info['abnormal_types'].append('vx')
        
        # æ£€æµ‹vyå¼‚å¸¸é«˜é€Ÿ
        if len(vy_data) > 0:
            vy_abnormal = np.abs(vy_data) > LINEAR_SPEED_THRESHOLD
            abnormal_info['max_speeds']['vy'] = float(np.max(np.abs(vy_data)))
            abnormal_info['abnormal_frame_counts']['vy'] = int(np.sum(vy_abnormal))
            abnormal_info['abnormal_frame_percentages']['vy'] = float(np.sum(vy_abnormal) / total_frames * 100)
            
            if np.any(vy_abnormal):
                abnormal_info['has_abnormal_speed'] = True
                abnormal_info['abnormal_types'].append('vy')
        
        # æ£€æµ‹vyawå¼‚å¸¸é«˜é€Ÿ
        if len(vyaw_data) > 0:
            vyaw_abnormal = np.abs(vyaw_data) > ANGULAR_SPEED_THRESHOLD
            abnormal_info['max_speeds']['vyaw'] = float(np.max(np.abs(vyaw_data)))
            abnormal_info['abnormal_frame_counts']['vyaw'] = int(np.sum(vyaw_abnormal))
            abnormal_info['abnormal_frame_percentages']['vyaw'] = float(np.sum(vyaw_abnormal) / total_frames * 100)
            
            if np.any(vyaw_abnormal):
                abnormal_info['has_abnormal_speed'] = True
                abnormal_info['abnormal_types'].append('vyaw')
        
        # æ£€æµ‹é€Ÿåº¦å¹…å€¼å¼‚å¸¸é«˜é€Ÿ
        if len(vx_data) > 0 and len(vy_data) > 0:
            speed_magnitude = np.sqrt(vx_data**2 + vy_data**2)
            speed_abnormal = speed_magnitude > LINEAR_SPEED_THRESHOLD
            abnormal_info['max_speeds']['speed_magnitude'] = float(np.max(speed_magnitude))
            abnormal_info['abnormal_frame_counts']['speed_magnitude'] = int(np.sum(speed_abnormal))
            abnormal_info['abnormal_frame_percentages']['speed_magnitude'] = float(np.sum(speed_abnormal) / total_frames * 100)
            
            if np.any(speed_abnormal):
                abnormal_info['has_abnormal_speed'] = True
                if 'speed_magnitude' not in abnormal_info['abnormal_types']:
                    abnormal_info['abnormal_types'].append('speed_magnitude')
        
        return abnormal_info
    
    def analyze_all_data(self, processed_data_dir):
        """
        åˆ†ææ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®
        
        Args:
            processed_data_dir: å¤„ç†æ•°æ®çš„æ ¹ç›®å½•
        """
        print(f"ğŸ” å¼€å§‹åˆ†ææ•°æ®ç›®å½•: {processed_data_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
        json_files = self.find_processed_json_files(processed_data_dir)
        
        if not json_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å¤„ç†è¿‡çš„JSONæ–‡ä»¶")
            return
        
        # é‡ç½®æ•°æ®
        self.car_pose_data = {'x': [], 'y': [], 'angle': []}
        self.velocity_data = {'vx': [], 'vy': [], 'vyaw': []}
        self.trajectory_stats = []
        self.abnormal_speed_trajectories = []  # ğŸ¯ é‡ç½®å¼‚å¸¸é«˜é€Ÿè½¨è¿¹åˆ—è¡¨
        self.total_trajectories = 0
        self.total_frames = 0
        
        # é€ä¸ªåˆ†æJSONæ–‡ä»¶
        print("ğŸ“Š æ­£åœ¨åˆ†æè½¨è¿¹æ•°æ®...")
        for json_path in tqdm(json_files, desc="åˆ†æè¿›åº¦"):
            result = self.load_and_analyze_json(json_path)
            
            if result is not None:
                # ç´¯ç§¯å…¨å±€æ•°æ®
                for key in self.car_pose_data:
                    self.car_pose_data[key].extend(result['car_pose_data'][key])
                
                for key in self.velocity_data:
                    self.velocity_data[key].extend(result['velocity_data'][key])
                
                # ä¿å­˜è½¨è¿¹ç»Ÿè®¡
                trajectory_stat = result['trajectory_stat']
                self.trajectory_stats.append(trajectory_stat)
                
                # ğŸ¯ æ–°å¢ï¼šè®°å½•å¼‚å¸¸é«˜é€Ÿè½¨è¿¹
                if trajectory_stat['abnormal_speed_info']['has_abnormal_speed']:
                    self.abnormal_speed_trajectories.append({
                        'file_path': trajectory_stat['file_path'],
                        'trajectory_name': trajectory_stat['trajectory_name'],
                        'abnormal_types': trajectory_stat['abnormal_speed_info']['abnormal_types'],
                        'max_speeds': trajectory_stat['abnormal_speed_info']['max_speeds'],
                        'abnormal_frame_counts': trajectory_stat['abnormal_speed_info']['abnormal_frame_counts'],
                        'abnormal_frame_percentages': trajectory_stat['abnormal_speed_info']['abnormal_frame_percentages']
                    })
                
                self.total_trajectories += 1
                self.total_frames += trajectory_stat['num_frames']
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        for key in self.car_pose_data:
            self.car_pose_data[key] = np.array(self.car_pose_data[key])
        for key in self.velocity_data:
            self.velocity_data[key] = np.array(self.velocity_data[key])
        
        print(f"âœ… åˆ†æå®Œæˆ!")
        print(f"ğŸ“ˆ æ€»è®¡: {self.total_trajectories} æ¡è½¨è¿¹, {self.total_frames} å¸§æ•°æ®")
        print(f"âš ï¸  å¼‚å¸¸é«˜é€Ÿè½¨è¿¹: {len(self.abnormal_speed_trajectories)} æ¡ ({len(self.abnormal_speed_trajectories)/max(self.total_trajectories, 1)*100:.1f}%)")
    
    def calculate_global_statistics(self):
        """
        è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å…¨å±€ç»Ÿè®¡å­—å…¸
        """
        global_stats = {
            'summary': {
                'total_trajectories': self.total_trajectories,
                'total_frames': self.total_frames,
                'avg_frames_per_trajectory': self.total_frames / max(self.total_trajectories, 1)
            },
            'car_pose': {},
            'velocity_decomposed': {}
        }
        
        # Car poseå…¨å±€ç»Ÿè®¡
        for key, values in self.car_pose_data.items():
            if len(values) > 0:
                global_stats['car_pose'][key] = {
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'median': float(np.median(values)),
                    'percentile_25': float(np.percentile(values, 25)),
                    'percentile_75': float(np.percentile(values, 75)),
                    'range': float(np.max(values) - np.min(values)),
                    'total_samples': len(values)
                }
        
        # Velocityå…¨å±€ç»Ÿè®¡
        for key, values in self.velocity_data.items():
            if len(values) > 0:
                global_stats['velocity_decomposed'][key] = {
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'median': float(np.median(values)),
                    'percentile_25': float(np.percentile(values, 25)),
                    'percentile_75': float(np.percentile(values, 75)),
                    'range': float(np.max(values) - np.min(values)),
                    'total_samples': len(values)
                }
        
        return global_stats
    
    def calculate_distribution_percentages(self):
        """
        è®¡ç®—æ•°æ®åˆ†å¸ƒç™¾åˆ†æ¯”
        
        Returns:
            åˆ†å¸ƒç™¾åˆ†æ¯”å­—å…¸
        """
        distribution_stats = {
            'velocity_distribution': {},
            'car_pose_distribution': {},
            'abnormal_speed_analysis': {}  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿåˆ†æ
        }
        
        # ğŸ¯ æ–°å¢ï¼šå¼‚å¸¸é«˜é€Ÿåˆ†æ
        LINEAR_SPEED_THRESHOLD = 0.5  # m/s
        ANGULAR_SPEED_THRESHOLD = 0.6  # rad/s
        
        abnormal_speed_stats = {
            'linear_speed_threshold': LINEAR_SPEED_THRESHOLD,
            'angular_speed_threshold': ANGULAR_SPEED_THRESHOLD,
            'total_trajectories': self.total_trajectories,
            'abnormal_trajectories_count': len(self.abnormal_speed_trajectories),
            'abnormal_trajectories_percentage': len(self.abnormal_speed_trajectories) / max(self.total_trajectories, 1) * 100,
            'abnormal_trajectory_details': self.abnormal_speed_trajectories
        }
        
        # å…¨å±€å¼‚å¸¸é«˜é€Ÿå¸§ç»Ÿè®¡
        global_abnormal_frames = {
            'vx': 0, 'vy': 0, 'vyaw': 0, 'speed_magnitude': 0
        }
        
        # è®¡ç®—å…¨å±€å¼‚å¸¸é«˜é€Ÿå¸§æ•°
        if 'vx' in self.velocity_data and len(self.velocity_data['vx']) > 0:
            global_abnormal_frames['vx'] = int(np.sum(np.abs(self.velocity_data['vx']) > LINEAR_SPEED_THRESHOLD))
        if 'vy' in self.velocity_data and len(self.velocity_data['vy']) > 0:
            global_abnormal_frames['vy'] = int(np.sum(np.abs(self.velocity_data['vy']) > LINEAR_SPEED_THRESHOLD))
        if 'vyaw' in self.velocity_data and len(self.velocity_data['vyaw']) > 0:
            global_abnormal_frames['vyaw'] = int(np.sum(np.abs(self.velocity_data['vyaw']) > ANGULAR_SPEED_THRESHOLD))
        if 'vx' in self.velocity_data and 'vy' in self.velocity_data:
            vx_data = self.velocity_data['vx']
            vy_data = self.velocity_data['vy']
            if len(vx_data) > 0 and len(vy_data) > 0:
                speed_magnitude = np.sqrt(vx_data**2 + vy_data**2)
                global_abnormal_frames['speed_magnitude'] = int(np.sum(speed_magnitude > LINEAR_SPEED_THRESHOLD))
        
        abnormal_speed_stats['global_abnormal_frame_counts'] = global_abnormal_frames
        abnormal_speed_stats['global_abnormal_frame_percentages'] = {
            key: count / max(self.total_frames, 1) * 100 
            for key, count in global_abnormal_frames.items()
        }
        
        distribution_stats['abnormal_speed_analysis'] = abnormal_speed_stats
        
        # åŸæœ‰çš„é€Ÿåº¦åˆ†å¸ƒåˆ†æ
        for key in ['vx', 'vy', 'vyaw']:
            if key in self.velocity_data:
                data = self.velocity_data[key]
                total_samples = len(data)
                
                if total_samples > 0:
                    # è®¡ç®—ä¸åŒèŒƒå›´çš„å æ¯”
                    near_zero = np.abs(data) < 0.01  # æ¥è¿‘é™æ­¢
                    low_speed = (np.abs(data) >= 0.01) & (np.abs(data) < 0.1)  # ä½é€Ÿ
                    medium_speed = (np.abs(data) >= 0.1) & (np.abs(data) < 0.3)  # ä¸­é€Ÿ
                    high_speed = (np.abs(data) >= 0.3) & (np.abs(data) < (LINEAR_SPEED_THRESHOLD if key in ['vx', 'vy'] else ANGULAR_SPEED_THRESHOLD))  # é«˜é€Ÿ
                    abnormal_high_speed = np.abs(data) >= (LINEAR_SPEED_THRESHOLD if key in ['vx', 'vy'] else ANGULAR_SPEED_THRESHOLD)  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿ
                    
                    # æ­£è´Ÿæ–¹å‘åˆ†æ
                    positive_vals = data > 0.01
                    negative_vals = data < -0.01
                    
                    # å¼‚å¸¸å€¼åˆ†æï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
                    mean_val = np.mean(data)
                    std_val = np.std(data)
                    outliers = np.abs(data - mean_val) > 3 * std_val
                    
                    distribution_stats['velocity_distribution'][key] = {
                        'near_zero_pct': float(np.sum(near_zero) / total_samples * 100),
                        'low_speed_pct': float(np.sum(low_speed) / total_samples * 100),
                        'medium_speed_pct': float(np.sum(medium_speed) / total_samples * 100),
                        'high_speed_pct': float(np.sum(high_speed) / total_samples * 100),
                        'abnormal_high_speed_pct': float(np.sum(abnormal_high_speed) / total_samples * 100),  # ğŸ¯ æ–°å¢
                        'positive_pct': float(np.sum(positive_vals) / total_samples * 100),
                        'negative_pct': float(np.sum(negative_vals) / total_samples * 100),
                        'outliers_pct': float(np.sum(outliers) / total_samples * 100),
                        'total_samples': total_samples
                    }
        
        # Car poseåˆ†å¸ƒåˆ†æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        for key in ['x', 'y']:
            if key in self.car_pose_data:
                data = self.car_pose_data[key]
                total_samples = len(data)
                
                if total_samples > 0:
                    # è®¡ç®—ä¸åŒèŒƒå›´çš„å æ¯”
                    near_origin = np.abs(data) < 0.1  # æ¥è¿‘åŸç‚¹
                    small_range = (np.abs(data) >= 0.1) & (np.abs(data) < 1.0)  # å°èŒƒå›´
                    medium_range = (np.abs(data) >= 1.0) & (np.abs(data) < 3.0)  # ä¸­ç­‰èŒƒå›´
                    large_range = np.abs(data) >= 3.0  # å¤§èŒƒå›´
                    
                    # æ­£è´Ÿæ–¹å‘åˆ†æ
                    positive_vals = data > 0.1
                    negative_vals = data < -0.1
                    
                    # å¼‚å¸¸å€¼åˆ†æ
                    mean_val = np.mean(data)
                    std_val = np.std(data)
                    outliers = np.abs(data - mean_val) > 3 * std_val
                    
                    distribution_stats['car_pose_distribution'][key] = {
                        'near_origin_pct': float(np.sum(near_origin) / total_samples * 100),
                        'small_range_pct': float(np.sum(small_range) / total_samples * 100),
                        'medium_range_pct': float(np.sum(medium_range) / total_samples * 100),
                        'large_range_pct': float(np.sum(large_range) / total_samples * 100),
                        'positive_pct': float(np.sum(positive_vals) / total_samples * 100),
                        'negative_pct': float(np.sum(negative_vals) / total_samples * 100),
                        'outliers_pct': float(np.sum(outliers) / total_samples * 100),
                        'total_samples': total_samples
                    }
        
        # è§’åº¦åˆ†å¸ƒåˆ†æï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if 'angle' in self.car_pose_data:
            angle_data = self.car_pose_data['angle']
            total_samples = len(angle_data)
            
            if total_samples > 0:
                # è±¡é™åˆ†æï¼ˆè€ƒè™‘è§’åº¦çš„å‘¨æœŸæ€§ï¼‰
                angle_normalized = (angle_data % (2 * np.pi))  # æ ‡å‡†åŒ–åˆ°[0, 2Ï€]
                
                q1 = (angle_normalized >= 0) & (angle_normalized < np.pi/2)  # ç¬¬ä¸€è±¡é™
                q2 = (angle_normalized >= np.pi/2) & (angle_normalized < np.pi)  # ç¬¬äºŒè±¡é™
                q3 = (angle_normalized >= np.pi) & (angle_normalized < 3*np.pi/2)  # ç¬¬ä¸‰è±¡é™
                q4 = (angle_normalized >= 3*np.pi/2) & (angle_normalized < 2*np.pi)  # ç¬¬å››è±¡é™
                
                # è§’åº¦å˜åŒ–èŒƒå›´åˆ†æ
                angle_range = np.max(angle_data) - np.min(angle_data)
                
                # å¼‚å¸¸å€¼åˆ†æ
                mean_val = np.mean(angle_data)
                std_val = np.std(angle_data)
                outliers = np.abs(angle_data - mean_val) > 3 * std_val
                
                distribution_stats['car_pose_distribution']['angle'] = {
                    'quadrant_1_pct': float(np.sum(q1) / total_samples * 100),
                    'quadrant_2_pct': float(np.sum(q2) / total_samples * 100),
                    'quadrant_3_pct': float(np.sum(q3) / total_samples * 100),
                    'quadrant_4_pct': float(np.sum(q4) / total_samples * 100),
                    'angle_range_rad': float(angle_range),
                    'angle_range_deg': float(angle_range * 180 / np.pi),
                    'outliers_pct': float(np.sum(outliers) / total_samples * 100),
                    'total_samples': total_samples
                }
        
        # é€Ÿåº¦å¹…å€¼åˆ†å¸ƒåˆ†æ
        if 'vx' in self.velocity_data and 'vy' in self.velocity_data:
            vx_data = self.velocity_data['vx']
            vy_data = self.velocity_data['vy']
            if len(vx_data) > 0 and len(vy_data) > 0:
                speed_magnitude = np.sqrt(vx_data**2 + vy_data**2)
                total_samples = len(speed_magnitude)
                
                # é€Ÿåº¦å¹…å€¼èŒƒå›´åˆ†æ
                stationary = speed_magnitude < 0.01  # é™æ­¢
                slow = (speed_magnitude >= 0.01) & (speed_magnitude < 0.1)  # ç¼“æ…¢
                normal = (speed_magnitude >= 0.1) & (speed_magnitude < 0.4)  # æ­£å¸¸
                fast = (speed_magnitude >= 0.4) & (speed_magnitude < LINEAR_SPEED_THRESHOLD)  # å¿«é€Ÿ
                abnormal_fast = speed_magnitude >= LINEAR_SPEED_THRESHOLD  # ğŸ¯ æ–°å¢å¼‚å¸¸å¿«é€Ÿ
                
                distribution_stats['velocity_distribution']['speed_magnitude'] = {
                    'stationary_pct': float(np.sum(stationary) / total_samples * 100),
                    'slow_pct': float(np.sum(slow) / total_samples * 100),
                    'normal_pct': float(np.sum(normal) / total_samples * 100),
                    'fast_pct': float(np.sum(fast) / total_samples * 100),
                    'abnormal_fast_pct': float(np.sum(abnormal_fast) / total_samples * 100),  # ğŸ¯ æ–°å¢
                    'max_speed': float(np.max(speed_magnitude)),
                    'avg_speed': float(np.mean(speed_magnitude)),
                    'total_samples': total_samples
                }
        
        return distribution_stats
    
    def create_velocity_histograms(self, output_dir, bins=50):
        """
        åˆ›å»ºé€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            bins: ç›´æ–¹å›¾binæ•°é‡
        """
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆé€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Velocity Distribution Analysis', fontsize=16, fontweight='bold')
        
        # vxåˆ†å¸ƒç›´æ–¹å›¾
        ax = axes[0, 0]
        vx_data = self.velocity_data['vx']
        if len(vx_data) > 0:
            n, bins_vx, patches = ax.hist(vx_data, bins=bins, alpha=0.7, color='blue', edgecolor='black')
            ax.axvline(np.mean(vx_data), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(vx_data):.3f}')
            ax.axvline(np.median(vx_data), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(vx_data):.3f}')
        ax.set_title('Forward Velocity (vx) Distribution', fontweight='bold')
        ax.set_xlabel('vx (m/s)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # vyåˆ†å¸ƒç›´æ–¹å›¾
        ax = axes[0, 1]
        vy_data = self.velocity_data['vy']
        if len(vy_data) > 0:
            n, bins_vy, patches = ax.hist(vy_data, bins=bins, alpha=0.7, color='green', edgecolor='black')
            ax.axvline(np.mean(vy_data), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(vy_data):.3f}')
            ax.axvline(np.median(vy_data), color='blue', linestyle='--', linewidth=2, label=f'Median: {np.median(vy_data):.3f}')
        ax.set_title('Lateral Velocity (vy) Distribution', fontweight='bold')
        ax.set_xlabel('vy (m/s)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # vyawåˆ†å¸ƒç›´æ–¹å›¾
        ax = axes[1, 0]
        vyaw_data = self.velocity_data['vyaw']
        if len(vyaw_data) > 0:
            n, bins_vyaw, patches = ax.hist(vyaw_data, bins=bins, alpha=0.7, color='red', edgecolor='black')
            ax.axvline(np.mean(vyaw_data), color='blue', linestyle='--', linewidth=2, label=f'Mean: {np.mean(vyaw_data):.3f}')
            ax.axvline(np.median(vyaw_data), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(vyaw_data):.3f}')
        ax.set_title('Angular Velocity (vyaw) Distribution', fontweight='bold')
        ax.set_xlabel('vyaw (rad/s)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # é€Ÿåº¦å¹…å€¼åˆ†å¸ƒç›´æ–¹å›¾
        ax = axes[1, 1]
        if len(vx_data) > 0 and len(vy_data) > 0:
            speed_magnitude = np.sqrt(vx_data**2 + vy_data**2)
            n, bins_speed, patches = ax.hist(speed_magnitude, bins=bins, alpha=0.7, color='purple', edgecolor='black')
            ax.axvline(np.mean(speed_magnitude), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(speed_magnitude):.3f}')
            ax.axvline(np.median(speed_magnitude), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(speed_magnitude):.3f}')
        ax.set_title('Speed Magnitude Distribution', fontweight='bold')
        ax.set_xlabel('Speed (m/s)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        histogram_path = os.path.join(output_dir, "velocity_distribution_histograms.png")
        plt.savefig(histogram_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… é€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾å·²ä¿å­˜: {histogram_path}")
    
    def create_car_pose_analysis(self, output_dir):
        """
        åˆ›å»ºcar_poseåˆ†æå›¾è¡¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆcar_poseåˆ†æå›¾è¡¨...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Car Pose Distribution Analysis', fontsize=16, fontweight='bold')
        
        # Xä½ç½®åˆ†å¸ƒ
        ax = axes[0, 0]
        x_data = self.car_pose_data['x']
        if len(x_data) > 0:
            ax.hist(x_data, bins=50, alpha=0.7, color='blue', edgecolor='black')
            ax.axvline(np.mean(x_data), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(x_data):.3f}')
            ax.axvline(np.median(x_data), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(x_data):.3f}')
        ax.set_title('X Position Distribution', fontweight='bold')
        ax.set_xlabel('X Position (m)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # Yä½ç½®åˆ†å¸ƒ
        ax = axes[0, 1]
        y_data = self.car_pose_data['y']
        if len(y_data) > 0:
            ax.hist(y_data, bins=50, alpha=0.7, color='green', edgecolor='black')
            ax.axvline(np.mean(y_data), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(y_data):.3f}')
            ax.axvline(np.median(y_data), color='blue', linestyle='--', linewidth=2, label=f'Median: {np.median(y_data):.3f}')
        ax.set_title('Y Position Distribution', fontweight='bold')
        ax.set_xlabel('Y Position (m)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # è§’åº¦åˆ†å¸ƒ
        ax = axes[1, 0]
        angle_data = self.car_pose_data['angle']
        if len(angle_data) > 0:
            ax.hist(angle_data, bins=50, alpha=0.7, color='red', edgecolor='black')
            ax.axvline(np.mean(angle_data), color='blue', linestyle='--', linewidth=2, label=f'Mean: {np.mean(angle_data):.3f}')
            ax.axvline(np.median(angle_data), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(angle_data):.3f}')
        ax.set_title('Angle Distribution', fontweight='bold')
        ax.set_xlabel('Angle (rad)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # ä½ç½®å¹…å€¼åˆ†å¸ƒ
        ax = axes[1, 1]
        if len(x_data) > 0 and len(y_data) > 0:
            position_magnitude = np.sqrt(x_data**2 + y_data**2)
            ax.hist(position_magnitude, bins=50, alpha=0.7, color='purple', edgecolor='black')
            ax.axvline(np.mean(position_magnitude), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(position_magnitude):.3f}')
            ax.axvline(np.median(position_magnitude), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(position_magnitude):.3f}')
        ax.set_title('Position Magnitude Distribution', fontweight='bold')
        ax.set_xlabel('Distance from Origin (m)')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        car_pose_path = os.path.join(output_dir, "car_pose_distribution_analysis.png")
        plt.savefig(car_pose_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Car poseåˆ†æå›¾è¡¨å·²ä¿å­˜: {car_pose_path}")
    
    def save_statistics_report(self, output_dir):
        """
        ä¿å­˜è¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        print("ğŸ“„ æ­£åœ¨ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        global_stats = self.calculate_global_statistics()
        
        # è®¡ç®—åˆ†å¸ƒç™¾åˆ†æ¯”
        distribution_stats = self.calculate_distribution_percentages()
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_path = os.path.join(output_dir, "statistics_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                'global_statistics': global_stats,
                'distribution_percentages': distribution_stats,
                'trajectory_statistics': self.trajectory_stats
            }, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆäººç±»å¯è¯»çš„æŠ¥å‘Š
        readable_report_path = os.path.join(output_dir, "statistics_report.txt")
        with open(readable_report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("æ•°æ®é›†ç»Ÿè®¡åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 80 + "\n\n")
            
            # æ€»ä½“ä¿¡æ¯
            f.write("ğŸ“Š æ€»ä½“ä¿¡æ¯:\n")
            f.write(f"  æ€»è½¨è¿¹æ•°: {global_stats['summary']['total_trajectories']}\n")
            f.write(f"  æ€»å¸§æ•°: {global_stats['summary']['total_frames']}\n")
            f.write(f"  å¹³å‡æ¯è½¨è¿¹å¸§æ•°: {global_stats['summary']['avg_frames_per_trajectory']:.1f}\n\n")
            
            # ğŸ¯ æ–°å¢ï¼šå¼‚å¸¸é«˜é€Ÿåˆ†æ
            f.write("ğŸ“ˆ å¼‚å¸¸é«˜é€Ÿåˆ†æ:\n")
            f.write(f"  å¼‚å¸¸é«˜é€Ÿé˜ˆå€¼: {distribution_stats['abnormal_speed_analysis']['linear_speed_threshold']:.2f} m/s å’Œ {distribution_stats['abnormal_speed_analysis']['angular_speed_threshold']:.2f} rad/s\n")
            f.write(f"  å¼‚å¸¸è½¨è¿¹æ•°: {distribution_stats['abnormal_speed_analysis']['abnormal_trajectories_count']}\n")
            f.write(f"  å¼‚å¸¸è½¨è¿¹ç™¾åˆ†æ¯”: {distribution_stats['abnormal_speed_analysis']['abnormal_trajectories_percentage']:.2f}%\n")
            
            # ğŸ¯ æ–°å¢ï¼šå¼‚å¸¸é«˜é€Ÿè½¨è¿¹è¯¦ç»†ä¿¡æ¯
            if len(self.abnormal_speed_trajectories) > 0:
                f.write(f"\n  å¼‚å¸¸é«˜é€Ÿè½¨è¿¹è¯¦ç»†ä¿¡æ¯:\n")
                for i, abnormal_traj in enumerate(self.abnormal_speed_trajectories):
                    f.write(f"    {i+1}. {abnormal_traj['trajectory_name']}\n")
                    f.write(f"       è·¯å¾„: {abnormal_traj['file_path']}\n")
                    f.write(f"       å¼‚å¸¸ç±»å‹: {', '.join(abnormal_traj['abnormal_types'])}\n")
                    f.write(f"       æœ€å¤§é€Ÿåº¦: ")
                    max_speed_info = []
                    for speed_type, max_val in abnormal_traj['max_speeds'].items():
                        if speed_type in ['vx', 'vy', 'speed_magnitude']:
                            max_speed_info.append(f"{speed_type}={max_val:.3f}m/s")
                        elif speed_type == 'vyaw':
                            max_speed_info.append(f"{speed_type}={max_val:.3f}rad/s")
                    f.write(", ".join(max_speed_info) + "\n")
                    
                    f.write(f"       å¼‚å¸¸å¸§æ•°: ")
                    abnormal_frame_info = []
                    for speed_type, count in abnormal_traj['abnormal_frame_counts'].items():
                        percentage = abnormal_traj['abnormal_frame_percentages'][speed_type]
                        abnormal_frame_info.append(f"{speed_type}={count}å¸§({percentage:.1f}%)")
                    f.write(", ".join(abnormal_frame_info) + "\n\n")
            else:
                f.write(f"  âœ… æ‰€æœ‰è½¨è¿¹é€Ÿåº¦å‡åœ¨æ­£å¸¸èŒƒå›´å†…\n")
            
            f.write("\n")
            
            # ğŸ¯ æ–°å¢ï¼šå…¨å±€å¼‚å¸¸é«˜é€Ÿå¸§ç»Ÿè®¡
            f.write("ğŸ“Š å…¨å±€å¼‚å¸¸é«˜é€Ÿå¸§ç»Ÿè®¡:\n")
            global_abnormal_frames = distribution_stats['abnormal_speed_analysis']['global_abnormal_frame_counts']
            global_abnormal_percentages = distribution_stats['abnormal_speed_analysis']['global_abnormal_frame_percentages']
            f.write(f"  VXå¼‚å¸¸é«˜é€Ÿå¸§: {global_abnormal_frames['vx']}å¸§ ({global_abnormal_percentages['vx']:.2f}%)\n")
            f.write(f"  VYå¼‚å¸¸é«˜é€Ÿå¸§: {global_abnormal_frames['vy']}å¸§ ({global_abnormal_percentages['vy']:.2f}%)\n")
            f.write(f"  VYAWå¼‚å¸¸é«˜é€Ÿå¸§: {global_abnormal_frames['vyaw']}å¸§ ({global_abnormal_percentages['vyaw']:.2f}%)\n")
            f.write(f"  é€Ÿåº¦å¹…å€¼å¼‚å¸¸é«˜é€Ÿå¸§: {global_abnormal_frames['speed_magnitude']}å¸§ ({global_abnormal_percentages['speed_magnitude']:.2f}%)\n\n")
            
            # Car poseç»Ÿè®¡
            f.write("ğŸš— Car Poseç»Ÿè®¡:\n")
            for key, stats in global_stats['car_pose'].items():
                f.write(f"  {key.upper()}:\n")
                f.write(f"    æœ€å°å€¼: {stats['min']:.6f}\n")
                f.write(f"    æœ€å¤§å€¼: {stats['max']:.6f}\n")
                f.write(f"    å¹³å‡å€¼: {stats['mean']:.6f}\n")
                f.write(f"    æ ‡å‡†å·®: {stats['std']:.6f}\n")
                f.write(f"    ä¸­ä½æ•°: {stats['median']:.6f}\n")
                f.write(f"    èŒƒå›´: {stats['range']:.6f}\n")
                f.write(f"    æ ·æœ¬æ•°: {stats['total_samples']}\n\n")
            
            # Velocityç»Ÿè®¡
            f.write("ğŸƒ Velocity Decomposedç»Ÿè®¡:\n")
            for key, stats in global_stats['velocity_decomposed'].items():
                f.write(f"  {key.upper()}:\n")
                f.write(f"    æœ€å°å€¼: {stats['min']:.6f}\n")
                f.write(f"    æœ€å¤§å€¼: {stats['max']:.6f}\n")
                f.write(f"    å¹³å‡å€¼: {stats['mean']:.6f}\n")
                f.write(f"    æ ‡å‡†å·®: {stats['std']:.6f}\n")
                f.write(f"    ä¸­ä½æ•°: {stats['median']:.6f}\n")
                f.write(f"    èŒƒå›´: {stats['range']:.6f}\n")
                f.write(f"    æ ·æœ¬æ•°: {stats['total_samples']}\n\n")
            
            # ğŸ¯ æ–°å¢ï¼šæ•°æ®åˆ†å¸ƒç™¾åˆ†æ¯”åˆ†æ
            f.write("ğŸ“ˆ æ•°æ®åˆ†å¸ƒç™¾åˆ†æ¯”åˆ†æ:\n")
            f.write("=" * 60 + "\n\n")
            
            # é€Ÿåº¦åˆ†å¸ƒç™¾åˆ†æ¯”
            f.write("ğŸš€ é€Ÿåº¦åˆ†å¸ƒç™¾åˆ†æ¯”:\n")
            for key, dist_stats in distribution_stats['velocity_distribution'].items():
                if key == 'speed_magnitude':
                    f.write(f"  SPEED MAGNITUDE (é€Ÿåº¦å¹…å€¼):\n")
                    f.write(f"    é™æ­¢çŠ¶æ€ (< 0.01 m/s): {dist_stats['stationary_pct']:.2f}%\n")
                    f.write(f"    ç¼“æ…¢ç§»åŠ¨ (0.01-0.1 m/s): {dist_stats['slow_pct']:.2f}%\n")
                    f.write(f"    æ­£å¸¸é€Ÿåº¦ (0.1-0.4 m/s): {dist_stats['normal_pct']:.2f}%\n")
                    f.write(f"    å¿«é€Ÿç§»åŠ¨ (0.4-0.5 m/s): {dist_stats['fast_pct']:.2f}%\n")
                    f.write(f"    å¼‚å¸¸é«˜é€Ÿ (â‰¥ 0.5 m/s): {dist_stats['abnormal_fast_pct']:.2f}%\n")  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿ
                    f.write(f"    æœ€å¤§é€Ÿåº¦: {dist_stats['max_speed']:.3f} m/s\n")
                    f.write(f"    å¹³å‡é€Ÿåº¦: {dist_stats['avg_speed']:.3f} m/s\n\n")
                else:
                    f.write(f"  {key.upper()}:\n")
                    f.write(f"    æ¥è¿‘é›¶ (< 0.01): {dist_stats['near_zero_pct']:.2f}%\n")
                    f.write(f"    ä½é€Ÿ (0.01-0.1): {dist_stats['low_speed_pct']:.2f}%\n")
                    f.write(f"    ä¸­é€Ÿ (0.1-0.3): {dist_stats['medium_speed_pct']:.2f}%\n")
                    if key in ['vx', 'vy']:
                        f.write(f"    é«˜é€Ÿ (0.3-0.5): {dist_stats['high_speed_pct']:.2f}%\n")
                        f.write(f"    å¼‚å¸¸é«˜é€Ÿ (â‰¥ 0.5): {dist_stats['abnormal_high_speed_pct']:.2f}%\n")  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿ
                    else:  # vyaw
                        f.write(f"    é«˜é€Ÿ (0.3-0.6): {dist_stats['high_speed_pct']:.2f}%\n")
                        f.write(f"    å¼‚å¸¸é«˜é€Ÿ (â‰¥ 0.6): {dist_stats['abnormal_high_speed_pct']:.2f}%\n")  # ğŸ¯ æ–°å¢å¼‚å¸¸é«˜é€Ÿ
                    f.write(f"    æ­£å‘è¿åŠ¨: {dist_stats['positive_pct']:.2f}%\n")
                    f.write(f"    è´Ÿå‘è¿åŠ¨: {dist_stats['negative_pct']:.2f}%\n")
                    f.write(f"    å¼‚å¸¸å€¼ (Â±3Ïƒ): {dist_stats['outliers_pct']:.2f}%\n\n")
            
            # ä½ç½®åˆ†å¸ƒç™¾åˆ†æ¯”
            f.write("ğŸ“ ä½ç½®åˆ†å¸ƒç™¾åˆ†æ¯”:\n")
            for key, dist_stats in distribution_stats['car_pose_distribution'].items():
                if key == 'angle':
                    f.write(f"  ANGLE (è§’åº¦):\n")
                    f.write(f"    ç¬¬ä¸€è±¡é™ (0-90Â°): {dist_stats['quadrant_1_pct']:.2f}%\n")
                    f.write(f"    ç¬¬äºŒè±¡é™ (90-180Â°): {dist_stats['quadrant_2_pct']:.2f}%\n")
                    f.write(f"    ç¬¬ä¸‰è±¡é™ (180-270Â°): {dist_stats['quadrant_3_pct']:.2f}%\n")
                    f.write(f"    ç¬¬å››è±¡é™ (270-360Â°): {dist_stats['quadrant_4_pct']:.2f}%\n")
                    f.write(f"    è§’åº¦å˜åŒ–èŒƒå›´: {dist_stats['angle_range_deg']:.1f}Â° ({dist_stats['angle_range_rad']:.3f} rad)\n")
                    f.write(f"    å¼‚å¸¸å€¼ (Â±3Ïƒ): {dist_stats['outliers_pct']:.2f}%\n\n")
                else:
                    f.write(f"  {key.upper()}:\n")
                    f.write(f"    æ¥è¿‘åŸç‚¹ (< 0.1m): {dist_stats['near_origin_pct']:.2f}%\n")
                    f.write(f"    å°èŒƒå›´ (0.1-1.0m): {dist_stats['small_range_pct']:.2f}%\n")
                    f.write(f"    ä¸­ç­‰èŒƒå›´ (1.0-3.0m): {dist_stats['medium_range_pct']:.2f}%\n")
                    f.write(f"    å¤§èŒƒå›´ (â‰¥ 3.0m): {dist_stats['large_range_pct']:.2f}%\n")
                    f.write(f"    æ­£å‘ä½ç½®: {dist_stats['positive_pct']:.2f}%\n")
                    f.write(f"    è´Ÿå‘ä½ç½®: {dist_stats['negative_pct']:.2f}%\n")
                    f.write(f"    å¼‚å¸¸å€¼ (Â±3Ïƒ): {dist_stats['outliers_pct']:.2f}%\n\n")
            
            f.write("=" * 60 + "\n\n")
            
            # å»æ‰è½¨è¿¹çº§åˆ«ç»Ÿè®¡çš„æ‰“å°
            # f.write("ğŸ“ˆ è½¨è¿¹çº§åˆ«ç»Ÿè®¡ (å‰10æ¡è½¨è¿¹):\n")
            # for i, traj_stat in enumerate(self.trajectory_stats[:10]):
            #     f.write(f"  {i+1}. {traj_stat['trajectory_name']} ({traj_stat['num_frames']} å¸§)\n")
        
        print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   JSONæ ¼å¼: {report_path}")
        print(f"   æ–‡æœ¬æ ¼å¼: {readable_report_path}")
        
        return global_stats
    
    def print_summary(self, global_stats):
        """
        æ‰“å°ç»Ÿè®¡æ‘˜è¦
        
        Args:
            global_stats: å…¨å±€ç»Ÿè®¡å­—å…¸
        """
        print("\n" + "=" * 80)
        print("ğŸ“Š æ•°æ®é›†åˆ†ææ‘˜è¦")
        print("=" * 80)
        
        print(f"ğŸ“ˆ æ€»ä½“ä¿¡æ¯:")
        print(f"   æ€»è½¨è¿¹æ•°: {global_stats['summary']['total_trajectories']}")
        print(f"   æ€»å¸§æ•°: {global_stats['summary']['total_frames']}")
        print(f"   å¹³å‡æ¯è½¨è¿¹å¸§æ•°: {global_stats['summary']['avg_frames_per_trajectory']:.1f}")
        
        print(f"\nğŸš— Car PoseèŒƒå›´:")
        for key, stats in global_stats['car_pose'].items():
            print(f"   {key.upper()}: [{stats['min']:.3f}, {stats['max']:.3f}] (å‡å€¼: {stats['mean']:.3f})")
        
        print(f"\nğŸƒ Velocity DecomposedèŒƒå›´:")
        for key, stats in global_stats['velocity_decomposed'].items():
            print(f"   {key.upper()}: [{stats['min']:.3f}, {stats['max']:.3f}] (å‡å€¼: {stats['mean']:.3f})")
        
        print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Dataset Analysis Tool - Analyze processed trajectory data')
    parser.add_argument('--processed_data_dir', default='./processed_data',
                       help='Directory containing processed trajectory data')
    parser.add_argument('--output_dir', default='./analysis_results',
                       help='Output directory for analysis results')
    parser.add_argument('--bins', type=int, default=50,
                       help='Number of bins for histograms')
    
    args = parser.parse_args()
    
    print(f"ğŸ¯ å¼€å§‹åˆ†æå¤„ç†æ•°æ®ç›®å½•: {args.processed_data_dir}")
    print(f"ğŸ“ åˆ†æç»“æœå°†ä¿å­˜åˆ°: {args.output_dir}")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DatasetAnalyzer()
    
    # åˆ†ææ‰€æœ‰æ•°æ®
    analyzer.analyze_all_data(args.processed_data_dir)
    
    if analyzer.total_trajectories == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è½¨è¿¹æ•°æ®")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ç”Ÿæˆåˆ†æç»“æœ
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆåˆ†æç»“æœ...")
    
    # 1. ç”Ÿæˆé€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾
    analyzer.create_velocity_histograms(args.output_dir, bins=args.bins)
    
    # 2. ç”Ÿæˆcar_poseåˆ†æå›¾è¡¨
    analyzer.create_car_pose_analysis(args.output_dir)
    
    # 3. ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    global_stats = analyzer.save_statistics_report(args.output_dir)
    
    # 4. æ‰“å°æ‘˜è¦
    analyzer.print_summary(global_stats)
    
    print(f"\nğŸ‰ æ•°æ®åˆ†æå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {args.output_dir}")


if __name__ == "__main__":
    main() 